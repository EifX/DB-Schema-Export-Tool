# Required: Directory to save the schema files
O=F:\Cached_DBSchema_PgSql

# Required: Database server name; assumed to be Microsoft SQL Server unless /PgUser is provided
Server=Proteinseqs

ExistingDDL=Manager_Control.sql

# With SQL Server databases, dump table data using COPY commands instead of INSERT INTO statements.  With PostgreSQL data, dump table data using pg_dump and COPY commands.
PgDump=True

# Number of values to insert at a time when PgInsert is true for a table; only applicable when exporting data from SQL Server
PgInsertChunkSize=5000

# With SQL Server databases, while reading the TableDataToExport.txt file, default the PgInsert column to true, meaning table data will be exported via INSERT INTO statements using the ON CONFLICT (key_column) DO UPDATE SET syntax. Ignored for PostgreSQL data
PgInsert=True

# Database name (alternatively, use DBList for a list of databases)
DB=Manager_Control

# Prefix name for output directories; default name is DBSchema__DatabaseName
DirectoryPrefix=DBSchema__

# Skip exporting schema
NoSchema=False

# Disable creating a subdirectory for each database when copying data to the Sync directory
NoSubdirectory=False

# Create a directory for the schema files for each database
CreateDBDirectories=True

# Export server settings, logins, and jobs
ServerInfo=False

# Text file with table names (one name per line) for which table data should be exported. Also supports a multi-column, tab-delimited format:\nSourceTableName TargetSchemaName TargetTableName PgInsert KeyColumn(s)
Data=Manager_Control_Tables.tsv

# Text file mapping source column names to target column names. Tab-delimited columns are:\nSourceTableName  SourceColumnName  TargetColumnName\nThe TargetColumn supports <Skip> for not including the given column in the output file
Map=Manager_Control_Table_Columns.tsv

# Default schema for exported tables and data. If undefined, use the original table's schema
DefaultSchema=mc

# In addition to table names defined in /Data, there are default tables which will have their data exported. Disable the defaults using /NoAutoData
NoAutoData=False

# Export data from every table in the database
ExportAllData=True

# Maximum number of rows of data to export; defaults to 1000
MaxRows=1000

# Generate a bash script for loading table data
ScriptLoad=True

# Auto changes column names from Upper_Case and UpperCase to lower_case when exporting table data
SnakeCase=True

# Copy new/changed files from the output directory to an alternative directory. This is advantageous to prevent file timestamps from getting updated every time the schema is exported.
Sync=

# Auto-update any new or changed files using Git
Git=False

# Commit any updates to the repository
Commit=False

# Log messages to a file; specify a log file name using /LogFile:LogFilePath
L=False

# Log file name
LogFile=

# Specify the directory to save the log file in; by default, the log file is created in the current working directory
LogDir=

# Count the number of database objects that would be exported
Preview=False

# Show (but do not log) export stats
Stats=False
